{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "202011050_IRAssignment2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEBZIo6Hu9GP"
      },
      "source": [
        "# **Import All the Required Libraries here**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvU6EZq3vKLK",
        "outputId": "b9efddd6-c148-44c1-a302-c521108cbb2b"
      },
      "source": [
        "import os\r\n",
        "import re\r\n",
        "import math\r\n",
        "import numpy as np\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "import nltk\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem import PorterStemmer,WordNetLemmatizer\r\n",
        "import pandas as pd\r\n",
        "from IPython.display import display\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('wordnet')\r\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3YKyQDls5oK"
      },
      "source": [
        "# 1.**Making class for Preprocessing Data**\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeHYMHcbtJJB"
      },
      "source": [
        "class Preprocessing:\r\n",
        "  \r\n",
        "  #To Load the Data \r\n",
        "\r\n",
        "  def load_data(self):\r\n",
        "    global doc\r\n",
        "    doc = list()\r\n",
        "    k=os.listdir(\"business\")\r\n",
        "    k=sorted(k)\r\n",
        "    data=list()\r\n",
        "    for name in k:\r\n",
        "      ##check if name contains index type files or not\r\n",
        "\r\n",
        "      check = re.findall(\"index\",str(name))\r\n",
        "      if len(check) != 0:  ##contains index then continue and ignore this file\r\n",
        "         continue\r\n",
        "      #while listing the files we have to ignore these two files in the colab\r\n",
        "      if name == '.config' or name == 'sample_data':\r\n",
        "        continue\r\n",
        "      else:\r\n",
        "        f = open(\"business/\"+ name,'r')\r\n",
        "        soup = BeautifulSoup(f,\"html.parser\")\r\n",
        "        required_data = soup.find(\"text\")\r\n",
        "        temp = required_data.text\r\n",
        "        #check if document contains any words or not\r\n",
        "        check = re.findall(\"[A-Za-z0-9]\",temp)\r\n",
        "        if len(check) == 0:\r\n",
        "          continue\r\n",
        "        data.append(temp)       \r\n",
        "        doc_id = soup.find(\"docno\")\r\n",
        "        doc.append(doc_id)\r\n",
        "\r\n",
        "    return data\r\n",
        "\r\n",
        "    \r\n",
        "  #function for removing numerical and punctuation from data\r\n",
        "  def remove_num_punc(self,data):\r\n",
        "      #retrieving each doc data and then removing numerical and punctuation from each document\r\n",
        "      \r\n",
        "      for i,doc_text in zip(range(len(data)),data):\r\n",
        "        \r\n",
        "        doc_text = re.sub(r'[^\\w\\s]', '',doc_text)\r\n",
        "        doc_text = re.sub('\\d','',doc_text)\r\n",
        "        data[i] = doc_text\r\n",
        "      return data\r\n",
        "\r\n",
        "    \r\n",
        "  #function for performing tokenization using nltk library\r\n",
        "  def process_token(self,data):\r\n",
        "      for i,doc_text in zip(range(len(data)),data):\r\n",
        "        data_tokenized = nltk.word_tokenize(doc_text)\r\n",
        "        data[i] = data_tokenized\r\n",
        "      return data \r\n",
        "    \r\n",
        "    \r\n",
        "\r\n",
        "  #function for converting to lower case letter \r\n",
        "  def convert_to_lower(self,data):\r\n",
        "      #converting to lower case letter\r\n",
        "      for i,doc_text in zip(range(len(data)),data):\r\n",
        "        data_smallcase = [word.lower() for word in doc_text]\r\n",
        "        data[i] = data_smallcase\r\n",
        "      return data\r\n",
        "   \r\n",
        "\r\n",
        "  #function for removing stop words \r\n",
        "  def remove_stop_words(self,data):\r\n",
        "      stop_words = stopwords.words('english')\r\n",
        "      \r\n",
        "      for i,doc_text in zip(range(len(data)),data):\r\n",
        "        data_without_stopwords  = list()\r\n",
        "        for word in doc_text:\r\n",
        "          if word not in stop_words:\r\n",
        "            data_without_stopwords.append(word)\r\n",
        "        data[i] = data_without_stopwords\r\n",
        "      return data  \r\n",
        "\r\n",
        "    \r\n",
        "  #function to perform lemmatization \r\n",
        "  def perform_lemmatization(self,data_without_stopwords):\r\n",
        "      lemmatizer = WordNetLemmatizer()\r\n",
        "          \r\n",
        "      after_data = list()\r\n",
        "      \r\n",
        "      for k,word_list in zip(range(len(data_without_stopwords)),data_without_stopwords):\r\n",
        "        after_lemmatize = list()\r\n",
        "        \r\n",
        "        i=0\r\n",
        "        while i < len(word_list):\r\n",
        "          word = data_without_stopwords[k][i]\r\n",
        "          after_lemmatize.append(lemmatizer.lemmatize(word,pos='v'))\r\n",
        "          i += 1\r\n",
        "        after_data.append(after_lemmatize)\r\n",
        "        #data_without_stopwords[k][:] = after_lemmatize\r\n",
        "      return after_data    \r\n",
        "  \r\n",
        "\r\n",
        " "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdoIRrZStOBn"
      },
      "source": [
        "# 2.Making use of Preprocessing class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkHLra4luFjQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cee17e8a-b2d2-43b6-f888-600546382aad"
      },
      "source": [
        "doc = list()\r\n",
        "#creating preprocessing object class\r\n",
        "obj=Preprocessing()\r\n",
        "\r\n",
        "#loading the data\r\n",
        "data = obj.load_data()\r\n",
        "\r\n",
        "#removing punctuation and numerical values\r\n",
        "data = obj.remove_num_punc(data)\r\n",
        "\r\n",
        "#performing tokenization on data using nltk library\r\n",
        "nltk_tokenize = obj.process_token(data)\r\n",
        "\r\n",
        "#converting to lower case\r\n",
        "data=obj.convert_to_lower(nltk_tokenize)\r\n",
        "\r\n",
        "#removing stop words from the data\r\n",
        "data = obj.remove_stop_words(data)\r\n",
        "\r\n",
        "#performing lemmatization\r\n",
        "lemmatized_data = obj.perform_lemmatization(data)\r\n",
        "\r\n",
        "print(lemmatized_data)\r\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['telegraph', 'calcutta', 'business', 'corporate', 'brief', 'kanoria', 'chemicals', 'industries', 'invest', 'rs', 'crore', 'set', 'mw', 'power', 'plant', 'chemical', 'unit', 'target', 'rs', 'crore', 'turnover', 'thermal', 'power', 'plant', 'would', 'set', 'outlay', 'rs', 'crore', 'chloralkali', 'plant', 'would', 'set', 'cost', 'rs', 'crore', 'chairman', 'manage', 'director', 'r', 'v', 'kanoria', 'say', 'hummingbird', 'ltd', 'lead', 'global', 'provider', 'integrate', 'enterprise', 'content', 'management', 'ecm', 'solutions', 'launch', 'comprehensive', 'content', 'library', 'consolidation', 'solution', 'law', 'firm', 'part', 'enterprise', 'content', 'integration', 'solution', 'solution', 'design', 'help', 'law', 'firm', 'library', 'consolidation', 'efforts', 'minimise', 'time', 'require', 'consolidation', 'ensure', 'complete', 'data', 'integrity', 'availability', 'throughout', 'process', 'canon', 'image', 'technology', 'company', 'draw', 'plan', 'capture', 'per', 'cent', 'rapidly', 'grow', 'market', 'colour', 'laser', 'multifunction', 'devices', 'india', 'market', 'estimate', 'rs', 'crore', 'sierra', 'atlantic', 'lead', 'player', 'offshoring', 'enterprise', 'applications', 'assess', 'fully', 'compliant', 'maturity', 'level', 'five', 'software', 'engineer', 'institute', 'sei', 'capability', 'mature', 'model', 'cmm', 'hikal', 'ltd', 'enter', 'longterm', 'arrangement', 'bayer', 'cropscience', 'ag', 'large', 'crop', 'protection', 'company', 'manufacture', 'supply', 'key', 'agrochemical', 'intermediate', 'hikal', 'set', 'manufacture', 'facility', 'mahad', 'maharashtra', 'manufacture', 'products', 'paltech', 'cool', 'tower', 'amp', 'equipments', 'ltd', 'iso', 'company', 'bag', 'national', 'award', 'quality', 'products', 'small', 'scale', 'sector', 'manage', 'director', 'ceo', 'h', 'p', 'yadav', 'receive', 'award', 'prime', 'minister', 'manmohan', 'singh', 'award', 'function', 'hold', 'recently', 'new', 'delhi', 'domestic', 'resources', 'department', 'back', 'office', 'operations', 'customer', 'relationship', 'management', 'cell', 'industrial', 'development', 'bank', 'india', 'idbi', 'accredit', 'iso', 'certification', 'quality', 'system', 'service', 'loan', 'raise', 'idbi', 'flexibonds', 'idbi', 'omni', 'bond', 'commercial', 'paper', 'certificate', 'deposit', 'corporate', 'deposit', 'slr', 'global', 'entrepolis', 'singapore', 'ges', 'island', 'nations', 'annual', 'mega', 'business', 'network', 'event', 'organise', 'singapore', 'economic', 'development', 'board', 'hold', 'october', 'india', 'strongly', 'represent', 'meet', 'tap', 'business', 'potential', 'advertisement'], ['telegraph', 'calcutta', 'business', 'chamber', 'happy', 'naths', 'trade', 'policy', 'bureaux', 'new', 'delhicalcutta', 'aug', 'chamber', 'commerce', 'welcome', 'new', 'foreign', 'trade', 'policy', 'announce', 'today', 'term', 'forward', 'look', 'gear', 'towards', 'export', 'competitiveness', 'confederation', 'indian', 'industry', 'cii', 'president', 'sunil', 'kant', 'munjal', 'say', 'foreign', 'trade', 'policy', 'comprehensive', 'challenge', 'forward', 'look', 'add', 'set', 'target', 'double', 'indias', 'share', 'global', 'trade', 'represent', 'vision', 'india', 'global', 'hub', 'manufacture', 'trade', 'service', 'specifically', 'cii', 'appreciate', 'special', 'initiatives', 'agriculture', 'gems', 'jewellery', 'handlooms', 'leather', 'footwear', 'benefit', 'extend', 'exportoriented', 'units', 'eous', 'ficci', 'president', 'yogendra', 'kumar', 'modi', 'say', 'policy', 'encompass', 'entire', 'export', 'chain', 'go', 'beyond', 'take', 'cognisance', 'indias', 'export', 'competitiveness', 'light', 'bilateral', 'multilateral', 'trade', 'process', 'country', 'enter', 'process', 'enter', 'mait', 'apex', 'body', 'represent', 'hardware', 'manufacture', 'industry', 'india', 'say', 'policy', 'lay', 'stress', 'promote', 'trade', 'also', 'create', 'economic', 'growth', 'focus', 'employment', 'generation', 'extend', 'significant', 'benefit', 'hardware', 'sector', 'favourable', 'modifications', 'eous', 'mait', 'executive', 'director', 'vinnie', 'mehta', 'say', 'perspective', 'hardware', 'manufacture', 'industry', 'exemption', 'eouehtp', 'cst', 'local', 'procurement', 'welcome', 'relief', 'enable', 'local', 'eouehtp', 'manufacturers', 'procure', 'components', 'raw', 'materials', 'par', 'global', 'competitors', 'react', 'policy', 'arun', 'jaitley', 'bjp', 'leader', 'former', 'union', 'commerce', 'minister', 'say', 'liberalisation', 'measure', 'tend', 'incentivise', 'foreign', 'trade', 'particular', 'export', 'however', 'fiscal', 'policy', 'important', 'tax', 'impact', 'global', 'competitiveness', 'export', 'add', 'increase', 'taxation', 'level', 'country', 'expect', 'products', 'high', 'tax', 'competitive', 'internationally', 'jaitley', 'say', 'engineer', 'export', 'promotion', 'council', 'eepc', 'chairman', 'rakesh', 'shah', 'say', 'way', 'achieve', 'target', 'per', 'cent', 'global', 'trade', 'make', 'country', 'manufacture', 'hub', 'step', 'take', 'new', 'policy', 'regard', 'epcg', 'scheme', 'would', 'go', 'long', 'way', 'achieve', 'target', 'indian', 'chamber', 'commerce', 'president', 'anup', 'singh', 'say', 'special', 'package', 'agriculture', 'scheme', 'like', 'vishesh', 'krishi', 'upaj', 'yojna', 'boost', 'export', 'fruit', 'vegetables', 'valueadded', 'products', 'federation', 'indian', 'exporters', 'association', 'today', 'term', 'policy', 'refresh', 'challenge', 'exporters', 'president', 'rafeeque', 'ahmed', 'say', 'policy', 'bold', 'sectorspecific', 'initiative', 'promote', 'export', 'well', 'generate', 'employment', 'pragati', 'maidan', 'government', 'draw', 'rs', 'crore', 'plan', 'convert', 'pragati', 'maidan', 'capital', 'worldclass', 'exhibition', 'convention', 'centre', 'commerce', 'minister', 'kamal', 'nath', 'say', 'new', 'complex', 'would', 'stateoftheart', 'environmentallycontrolled', 'visitor', 'friendly', 'exhibition', 'areas', 'marts', 'would', 'boast', 'huge', 'convention', 'centre', 'accommodate', 'delegate', 'flexible', 'hall', 'space', 'auditoria', 'meet', 'room', 'hitech', 'equipment', 'well', 'multilevel', 'car', 'park', 'vehicles', 'present', 'pragati', 'maidan', 'date', 'back', 'early', 'seventies', 'consider', 'mark', 'superb', 'serve', 'new', 'foreign', 'trade', 'policy', 'introduce', 'serve', 'india', 'scheme', 'give', 'fillip', 'service', 'export', 'essentially', 'revamp', 'version', 'earlier', 'dfec', 'scheme', 'service', 'scheme', 'individual', 'service', 'providers', 'earn', 'foreign', 'exchange', 'least', 'rs', 'lakh', 'service', 'providers', 'earn', 'exchange', 'least', 'rs', 'lakh', 'eligible', 'duty', 'credit', 'entitlement', 'per', 'cent', 'total', 'foreign', 'exchange', 'earn', 'case', 'standalone', 'restaurants', 'entitlement', 'shall', 'per', 'cent', 'case', 'hotels', 'limit', 'fix', 'per', 'cent', 'hotel', 'restaurants', 'use', 'duty', 'credit', 'entitlement', 'import', 'food', 'items', 'alcoholic', 'beverages'], ['telegraph', 'calcutta', 'business', 'new', 'centre', 'cost', 'patni', 'rs', 'cr', 'special', 'correspondent', 'mumbai', 'aug', 'patni', 'computer', 'systems', 'ltd', 'today', 'say', 'spend', 'close', 'rs', 'crore', 'set', 'software', 'development', 'centre', 'chennai', 'accommodate', 'professionals', 'support', 'service', 'patni', 'countrys', 'sixth', 'largest', 'information', 'technology', 'service', 'company', 'plan', 'set', 'centre', 'acre', 'plot', 'siruseri', 'park', 'promote', 'state', 'government', 'tamil', 'nadu', 'completion', 'patnis', 'second', 'largest', 'development', 'centre', 'country', 'propose', 'centre', 'add', 'patnis', 'multiple', 'delivery', 'facilities', 'anna', 'salai', 'chennai', 'bangalore', 'mumbai', 'navi', 'mumbai', 'pune', 'gandhinagar', 'noida', 'design', 'wellknown', 'architects', 'phase', 'one', 'project', 'complete', 'first', 'quarter', 'investment', 'around', 'rs', 'crore', 'capacity', 'accommodate', 'professionals', 'p', 'j', 'kutar', 'resident', 'director', 'india', 'say', 'patni', 'try', 'achieve', 'longterm', 'growth', 'continuously', 'invest', 'physical', 'infrastructure', 'domain', 'capabilities', 'new', 'service', 'line', 'current', 'financial', 'performance', 'exceed', 'overall', 'industry', 'growth', 'chennai', 'centre', 'play', 'crucial', 'role', 'achieve', 'add', 'new', 'centre', 'enable', 'company', 'ramp', 'operations', 'help', 'serve', 'big', 'clients', 'grow', 'verticals', 'financial', 'service', 'manufacture', 'insurance', 'patni', 'want', 'prefer', 'solution', 'provider', 'global', 'clients', 'choose', 'verticals', 'add', 'currently', 'employ', 'software', 'professionals', 'anna', 'salai', 'centre', 'company', 'concentrate', 'manufacture', 'insurance', 'bank', 'financial', 'service', 'retail', 'energy', 'utilities', 'industries', 'employee', 'strength', 'multiple', 'offshore', 'development', 'facilities', 'include', 'international', 'offices'], ['telegraph', 'calcutta', 'business', 'bharat', 'petrokrl', 'merger', 'back', 'table', 'special', 'correspondent', 'plan', 'stay', 'afloat', 'mumbai', 'aug', 'bharat', 'petroleum', 'corporation', 'ltd', 'take', 'relook', 'proposal', 'merge', 'kochi', 'refineries', 'ltd', 'merger', 'expect', 'improve', 'bharat', 'petros', 'bottomline', 'due', 'high', 'refine', 'margin', 'kochi', 'refineries', 'bharat', 'petro', 'chairman', 'manage', 'director', 'sarthak', 'behuria', 'say', 'postagm', 'press', 'conference', 'yesterday', 'behurias', 'comment', 'spark', 'rally', 'kochi', 'refineries', 'share', 'dalal', 'street', 'today', 'scrip', 'open', 'rs', 'hit', 'intraday', 'high', 'rs', 'end', 'rs', 'rs', 'per', 'cent', 'previous', 'close', 'counter', 'witness', 'trade', 'lakh', 'share', 'transact', 'bharat', 'petro', 'earlier', 'contemplate', 'merge', 'subsidiary', 'however', 'plan', 'put', 'backburner', 'previous', 'government', 'announce', 'public', 'offer', 'share', 'corporation', 'bharat', 'petro', 'hold', 'per', 'cent', 'stake', 'million', 'tonne', 'kochi', 'refineries', 'behuria', 'point', 'though', 'corporation', 'desire', 'merger', 'actively', 'pursue', 'many', 'approvals', 'require', 'however', 'bharat', 'petro', 'officials', 'say', 'merger', 'would', 'benefit', 'corporation', 'time', 'market', 'margins', 'bad', 'compensate', 'decent', 'refine', 'margin', 'talk', 'corporations', 'plan', 'sri', 'lanka', 'market', 'chairman', 'say', 'plan', 'proceed', 'track', 'negotiations', 'reach', 'final', 'stag', 'procedures', 'expect', 'complete', 'next', 'eight', 'weeks', 'add', 'bharat', 'petro', 'earlier', 'want', 'pay', 'million', 'pick', 'per', 'cent', 'stake', 'ceylon', 'petroleum', 'corporation', 'though', 'opposition', 'deal', 'various', 'sri', 'lankan', 'political', 'party', 'island', 'nations', 'government', 'recently', 'clarify', 'go', 'ahead', 'deal', 'speak', 'impact', 'high', 'crudeoil', 'price', 'bpcl', 'chief', 'indicate', 'price', 'continue', 'remain', 'high', 'level', 'may', 'hit', 'corporations', 'profit', 'meanwhile', 'bharat', 'petro', 'seek', 'additional', 'supply', 'crude', 'oil', 'malaysia', 'also', 'plan', 'enter', 'deal', 'libya', 'bring', 'dependence', 'west', 'asia', 'chairman', 'say', 'bharat', 'petro', 'plan', 'increase', 'spread', 'move', 'away', 'west', 'asia', 'look', 'source', 'point', 'point', 'oil', 'security', 'issue', 'corporation', 'negotiate', 'madhya', 'pradesh', 'government', 'regard', 'salestax', 'concessions', 'bina', 'refinery', 'earlier', 'address', 'shareholders', 'bharat', 'petroleums', 'annual', 'general', 'meet', 'chairman', 'say', 'recent', 'duty', 'reductions', 'centre', 'bring', 'cost', 'purchase', 'market', 'company', 'partially', 'help', 'oil', 'firm', 'maintain', 'price', 'domestic', 'market', 'however', 'case', 'international', 'price', 'keep', 'escalate', 'current', 'domestic', 'price', 'would', 'inadequate', 'cover', 'cost', 'behuria', 'say'], ['telegraph', 'calcutta', 'business', 'mutual', 'fund', 'fund', 'equity', 'diversify', 'nav', 'change', 'return', 'size', 'month', 'year', 'year', 'lifetime', 'alliance', 'basic', 'industries', 'alliance', 'equity', 'birla', 'advantage', 'birla', 'dividend', 'yield', 'plus', 'birla', 'india', 'opportunities', 'birla', 'mid', 'cap', 'birla', 'mnc', 'canbonus', 'cholamandalam', 'growth', 'deutsche', 'alpha', 'equity', 'dspml', 'equity', 'dspml', 'opportunities', 'dspml', 'tiger', 'dspml', 'top', 'equity', 'franklin', 'india', 'bluechip', 'franklin', 'india', 'opportunities', 'franklin', 'india', 'prima', 'franklin', 'india', 'prima', 'plus', 'gic', 'fortune', 'hdfc', 'capital', 'builder', 'hdfc', 'equity', 'hdfc', 'growth', 'fund', 'hdfc', 'top', 'hsbc', 'equity', 'hsbc', 'india', 'opportunities', 'ing', 'vysya', 'select', 'stock', 'kotak', 'kotak', 'global', 'india', 'licmf', 'equity', 'magnum', 'equity', 'magnum', 'multiplier', 'plus', 'principal', 'equity', 'principal', 'global', 'oppor', 'principal', 'growth', 'prudential', 'icici', 'growth', 'prudential', 'icici', 'power', 'reliance', 'bank', 'ril', 'diversifed', 'power', 'sector', 'reliance', 'growth', 'reliance', 'vision', 'sundaram', 'growth', 'sundaram', 'india', 'leadership', 'sundaram', 'select', 'focus', 'sundaram', 'select', 'midcap', 'tata', 'equity', 'opportunities', 'tata', 'equity', 'pe', 'tata', 'life', 'sciences', 'amp', 'tech', 'tata', 'pure', 'equity', 'tata', 'select', 'equity', 'taurus', 'starshare', 'templeton', 'india', 'growth', 'uti', 'auto', 'sector', 'uti', 'bank', 'sector', 'uti', 'basic', 'industries', 'uti', 'grandmaster', 'uti', 'growth', 'amp', 'value', 'uti', 'index', 'select', 'equity', 'uti', 'india', 'adv', 'equity', 'fund', 'uti', 'large', 'cap', 'uti', 'master', 'growth', 'uti', 'master', 'plus', 'uti', 'master', 'value', 'uti', 'mastergain', 'uti', 'mastershare', 'uti', 'mid', 'cap', 'uti', 'mnc', 'uti', 'pef', 'unit', 'scheme', 'uti', 'psu', 'uti', 'service', 'sector', 'equity', 'technology', 'alliance', 'new', 'millennium', 'franklin', 'infotech', 'kotak', 'tech', 'magnum', 'prudential', 'icici', 'technology', 'uti', 'software', 'hybrid', 'equityoriented', 'alliance', 'birla', 'balance', 'cantriple', 'dspml', 'balance', 'ft', 'india', 'balance', 'hdfc', 'balance', 'hdfc', 'prudence', 'licmf', 'ulis', 'magnum', 'balance', 'magnum', 'growth', 'principal', 'balance', 'prudential', 'icici', 'balance', 'tata', 'balance', 'unit', 'scheme', 'hybrid', 'debtoriented', 'cancigo', 'grihalaxmi', 'unit', 'plan', 'hdfc', 'childrens', 'giftsav', 'pru', 'icici', 'advisorcautious', 'tata', 'young', 'citizens', 'templeton', 'india', 'pension', 'unit', 'link', 'ins', 'plan', 'unit', 'scheme', 'uti', 'ccp', 'balance', 'uti', 'crts', 'uti', 'retirement', 'benefit', 'plan', 'uti', 'senior', 'citizens', 'plan', 'hybrid', 'asset', 'allocation', 'deutsche', 'invest', 'opportunity', 'prudential', 'icici', 'dynamic', 'uti', 'dynamic', 'equity', 'fund', 'uti', 'variable', 'investmentilp', 'debt', 'mediumterm', 'alliance', 'income', 'birla', 'income', 'plus', 'deutsche', 'premier', 'regular', 'dspml', 'bond', 'retail', 'grindlays', 'ssi', 'inv', 'grindlays', 'ssi', 'mediumterm', 'hdfc', 'high', 'interest', 'hdfc', 'income', 'hsbc', 'income', 'investment', 'ing', 'vysya', 'income', 'jm', 'income', 'kotak', 'bond', 'deposit', 'kotak', 'bond', 'wholesale', 'lic', 'bond', 'magnum', 'income', 'principal', 'income', 'prudential', 'icici', 'income', 'prudential', 'icici', 'income', 'lt', 'reliance', 'income', 'sundaram', 'bond', 'saver', 'tata', 'income', 'templeton', 'india', 'income', 'templeton', 'india', 'inc', 'builder', 'uti', 'bond', 'uti', 'bond', 'advantage', 'hybrid', 'monthly', 'income', 'alliance', 'mip', 'birla', 'mip', 'birla', 'mip', 'ii', 'wealth', 'dspml', 'sav', 'plus', 'moderate', 'ft', 'india', 'mip', 'hdfc', 'mip', 'longterm', 'hdfc', 'mip', 'shortterm', 'hsbc', 'mip', 'regular', 'hsbc', 'mip', 'save', 'jm', 'mipg', 'kotak', 'income', 'plus', 'lic', 'mip', 'magnum', 'mipg', 'principal', 'mip', 'principal', 'mip', 'plus', 'pru', 'icici', 'inc', 'multiplier', 'reg', 'prudential', 'icici', 'mip', 'reliance', 'mip', 'sundaram', 'mip', 'tata', 'mip', 'tata', 'mip', 'plus', 'templeton', 'mipdm', 'templeton', 'mipg', 'uti', 'mis', 'advantage', 'plan', 'uti', 'monthly', 'inc', 'scheme', 'gild', 'medium', 'amp', 'longterm', 'birla', 'gild', 'plus', 'pf', 'birla', 'gild', 'plus', 'regular', 'cangilt', 'pgs', 'chola', 'gild', 'investment', 'hdfc', 'gild', 'longterm', 'kotak', 'gild', 'investment', 'regular', 'licmf', 'gsf', 'magnum', 'gild', 'longtermdq', 'magnum', 'gild', 'longtermg', 'prud', 'icici', 'gild', 'investment', 'prud', 'icici', 'gild', 'invest', 'pf', 'tata', 'gsf', 'templeton', 'igsf', 'longterm', 'temp', 'india', 'gsf', 'composite', 'uti', 'gsec', 'debt', 'float', 'rate', 'dspml', 'float', 'rate', 'grindlays', 'float', 'rate', 'hdfc', 'float', 'rate', 'income', 'st', 'kotak', 'floater', 'shortterm', 'prud', 'icici', 'float', 'rate', 'b', 'templeton', 'float', 'rate', 'lt', 'templeton', 'float', 'rate', 'st', 'debt', 'ultra', 'shortterm', 'alliance', 'cash', 'manager', 'birla', 'cash', 'plus', 'retail', 'canliquid', 'retail', 'chola', 'liquid', 'deutsche', 'insta', 'cash', 'plus', 'grindlays', 'cash', 'hdfc', 'cash', 'mgmt', 'save', 'hdfc', 'cash', 'mgmt', 'sav', 'plus', 'hdfc', 'liquid', 'hsbc', 'cash', 'ing', 'vysya', 'liquid', 'jm', 'high', 'liquidity', 'kotak', 'liquid', 'regular', 'licmf', 'liquid', 'principal', 'cash', 'mgt', 'liquid', 'prudential', 'icici', 'liquid', 'reliance', 'liquid', 'treasury', 'sundaram', 'money', 'tata', 'liquid', 'templeton', 'india', 'tma', 'uti', 'liquid', 'advantage', 'uti', 'liquid', 'cash', 'regular', 'uti', 'money', 'market', 'mu', 'fund', 'net', 'asset', 'value', 'nav', 'august', 'scheme', 'mark', 'indicate', 'nav', 'previous', 'day', 'change', 'indicate', 'gainloss', 'rs', 'nav', 'previous', 'trade', 'day', 'lifetime', 'represent', 'return', 'per', 'cent', 'since', 'inception', 'month', 'year', 'return', 'absolute', 'year', 'lifetime', 'return', 'annualised', 'size', 'indicate', 'asset', 'management', 'rs', 'crore', 'source', 'value', 'research', 'wwwvalueresearchonlinecom'], ['telegraph', 'calcutta', 'business', 'ioc', 'bet', 'big', 'paradip', 'staff', 'reporter', 'leave', 'ibp', 'manage', 'director', 'g', 'kannan', 'chairman', 'ramachandran', 'director', 'prabh', 'das', 'calcutta', 'tuesday', 'picture', 'kishor', 'roy', 'chowdhury', 'calcutta', 'aug', 'indian', 'oil', 'corporation', 'ioc', 'plan', 'set', 'petrochemical', 'refinery', 'paradip', 'orissa', 'higher', 'capacity', 'initial', 'proposal', 'nine', 'million', 'tonnes', 'chairman', 'ramachandran', 'say', 'proposal', 'bigger', 'refinery', 'moot', 'achieve', 'economy', 'scale', 'initially', 'plan', 'nine', 'milliontonne', 'refinery', 'set', 'paradip', 'examine', 'possibilities', 'bigger', 'refinery', 'say', 'add', 'capacity', 'least', 'million', 'tonnes', 'achieve', 'economy', 'scale', 'however', 'rumour', 'round', 'company', 'weigh', 'options', 'set', 'milliontonne', 'capacity', 'refinery', 'investment', 'rs', 'crore', 'ramachandran', 'say', 'matter', 'take', 'board', 'level', 'october', 'ioc', 'plan', 'jerk', 'capacity', 'haldia', 'refinery', 'million', 'tonnes', 'million', 'tonnes', 'company', 'lay', 'pipeline', 'paradip', 'port', 'haldia', 'refinery', 'transport', 'crude', 'lower', 'cost', 'require', 'ship', 'company', 'also', 'plan', 'take', 'real', 'estate', 'close', 'unit', 'hindustan', 'fertiliser', 'haldia', 'get', 'haldia', 'petrochemicals', 'petrochemicals', 'complex', 'come', 'around', 'refinery', 'worldwide', 'say', 'paradip', 'plan', 'however', 'yet', 'receive', 'communication', 'bengal', 'government', 'haldia', 'petrochemicals', 'promoters', 'offer', 'say', 'earlier', 'ramachandran', 'chair', 'final', 'annual', 'general', 'meet', 'year', 'old', 'calcuttabased', 'ibp', 'ltd', 'present', 'strong', 'case', 'merger', 'ioc', 'subsidiary', 'ibp', 'felt', 'benefit', 'shareholders', 'latter', 'say', 'merger', 'process', 'complete', 'december', 'since', 'ibp', 'standalone', 'market', 'company', 'get', 'affect', 'especially', 'world', 'oil', 'price', 'go', 'tailspin', 'company', 'make', 'loss', 'rs', 'crore', 'first', 'quarter', 'perform', 'poorly', 'second', 'quarter', 'ramachandran', 'say', 'merger', 'benefit', 'ibp', 'immensely', 'refinery', 'linkages'], ['telegraph', 'calcutta', 'business', 'calcutta', 'link', 'chittagong', 'special', 'correspondent', 'new', 'delhi', 'aug', 'gmg', 'airline', 'bangladeshs', 'sole', 'private', 'airline', 'start', 'commercial', 'flight', 'india', 'next', 'week', 'part', 'plan', 'allow', 'private', 'carriers', 'nations', 'freedom', 'others', 'sky', 'gmg', 'plan', 'fly', 'thrice', 'week', 'southeastern', 'port', 'city', 'chittagong', 'calcutta', 'airline', 'plan', 'fly', 'monday', 'wednesday', 'friday', 'ticket', 'price', 'rs', 'plus', 'tax', 'gmg', 'flight', 'plan', 'clear', 'soon', 'bangladesh', 'allow', 'staterun', 'carrier', 'indian', 'airlines', 'increase', 'flight', 'frequency', 'dhaka', 'inaugural', 'flight', 'expect', 'take', 'september', 'gmg', 'hop', 'allow', 'fly', 'indian', 'cities', 'connect', 'capital', 'dhaka', 'delhi', 'mumbai', 'bangladesh', 'also', 'seek', 'right', 'national', 'carrier', 'fly', 'cities', 'include', 'guwahati', 'chennai', 'delhi', 'dhaka', 'also', 'clear', 'indias', 'sahara', 'airlines', 'jet', 'air', 'plan', 'link', 'calcutta', 'dhaka', 'daily', 'boeing', 'flight', 'however', 'indian', 'government', 'yet', 'make', 'mind', 'many', 'flight', 'ply', 'two', 'privately', 'run', 'indian', 'carriers', 'gmg', 'go', 'domestic', 'operation', 'join', 'biman', 'bangladesh', 'fly', 'eight', 'time', 'week', 'india', 'countrys', 'second', 'carrier', 'currently', 'biman', 'manage', 'use', 'per', 'cent', 'frequency', 'flight', 'allow', 'agreement', 'india', 'gmg', 'fleet', 'bombardiers', 'tie', 'delhibased', 'stic', 'market', 'india', 'connect', 'dhaka', 'daily', 'six', 'cities', 'bangladesh', 'chittagong', 'sylhet', 'jessore', 'rajshahi', 'barisal', 'cox', 'bazar', 'operate', 'flight', 'daily', 'average', 'one', 'landingtake', 'every', 'half', 'hour', 'government', 'want', 'encourage', 'airlines', 'friendly', 'neighbour', 'like', 'bangladesh', 'nepal', 'sri', 'lanka', 'southeast', 'asian', 'nations', 'like', 'thailand', 'keen', 'build', 'close', 'economic', 'cooperation', 'government', 'recently', 'sign', 'free', 'trade', 'pact', 'thailand', 'hop', 'ultimately', 'cover', 'nations', 'region', 'see', 'south', 'southeast', 'asia', 'key', 'market', 'drive', 'expand', 'share', 'global', 'trade', 'hop', 'open', 'sky', 'policy', 'friendly', 'neighbour', 'act', 'catalyst', 'process'], ['telegraph', 'calcutta', 'business', 'airtel', 'slash', 'postpaid', 'tariff', 'new', 'delhi', 'aug', 'pti', 'airtel', 'today', 'announce', 'new', 'mobile', 'tariff', 'postpaid', 'subscribers', 'slash', 'local', 'rat', 'airteltoairtel', 'network', 'avail', 'local', 'tariff', 'call', 'another', 'mobile', 'network', 'like', 'airtel', 'hutch', 'idea', 'subscribers', 'would', 'pay', 'rs', 'extra', 'per', 'month', 'plan', 'local', 'call', 'fix', 'phone', 'wll', 'would', 'cost', 'rs', 'monthly', 'rental', 'fix', 'rs', 'airtel', 'release', 'say', 'std', 'call', 'would', 'cost', 'rs', 'minute', 'airteltoairtel', 'rs', 'network', 'another', 'local', 'std', 'pack', 'scheme', 'airtel', 'offer', 'std', 'call', 'rs', 'per', 'minute', 'extra', 'rs', 'per', 'month', 'besides', 'rs', 'rental', 'pack', 'include', 'advantage', 'local', 'std', 'call', 'last', 'week', 'bsnl', 'slash', 'cellular', 'tariff', 'per', 'cent', 'low', 'paise', 'pulse', 'second', 'std', 'call', 'rs', 'minute', 'new', 'tariff', 'already', 'come', 'effect', 'bsnl', 'price', 'oppose', 'price', 'war', 'initiate', 'cellular', 'service', 'bsnl', 'airtel', 'today', 'accuse', 'stateowned', 'company', 'violate', 'trai', 'formula', 'slash', 'tariff', 'last', 'week', 'healthy', 'sign', 'industry', 'bsnl', 'able', 'slash', 'rat', 'get', 'access', 'deficit', 'charge', 'players', 'clearly', 'violation', 'trai', 'formula', 'fix', 'tariff', 'bharti', 'televentures', 'ltd', 'joint', 'manage', 'director', 'rajan', 'bharti', 'mittal', 'tell', 'reporters', 'launch', 'airtel', 'service', 'rajasthan', 'bharti', 'acquire', 'hexacom', 'india', 'limit', 'would', 'provide', 'service', 'brand', 'name', 'oasis', 'fight', 'price', 'alone', 'always', 'competitive', 'provide', 'technologically', 'perfect', 'innovative', 'service', 'customers', 'mittal', 'say'], ['telegraph', 'calcutta', 'business', 'corporate', 'brief', 'satyam', 'computer', 'service', 'ltd', 'launch', 'global', 'development', 'centre', 'gdc', 'melbourne', 'australia', 'company', 'largest', 'centre', 'outside', 'india', 'gdc', 'would', 'serve', 'major', 'technological', 'development', 'software', 'support', 'centre', 'company', 'asia', 'pacific', 'operations', 'satyam', 'inform', 'bombay', 'stock', 'exchange', 'neyveli', 'lignite', 'corporation', 'ltd', 'nlc', 'grant', 'mini', 'ratna', 'categoryi', 'status', 'enable', 'public', 'sector', 'company', 'accelerate', 'expansion', 'activities', 'ideal', 'play', 'abacus', 'india', 'pvt', 'ltd', 'launch', 'memory', 'programme', 'call', 'amaze', 'memory', 'emphasise', 'techniques', 'memorise', 'combine', 'usage', 'leave', 'right', 'side', 'brain', 'programme', 'level', 'start', 'basic', 'graduate', 'reliance', 'industries', 'bag', 'excellence', 'award', 'institute', 'national', 'association', 'software', 'service', 'company', 'nasscom', 'user', 'award', 'healthcare', 'present', 'wockhardt', 'hospital', 'amp', 'heart', 'institute', 'blue', 'dart', 'express', 'ltd', 'courier', 'service', 'major', 'strike', 'alliance', 'hayleys', 'group', 'sri', 'lanka', 'extend', 'footprint', 'island', 'country', 'alliance', 'would', 'enable', 'courier', 'company', 'service', 'widest', 'geographical', 'reach', 'two', 'countries', 'senior', 'vicepresident', 'tulsi', 'mirchandaney', 'say', 'oriental', 'insurance', 'recruit', 'agents', 'mumbai', 'march', 'talk', 'company', 'tieups', 'extend', 'insurance', 'cover', 'domestic', 'appliances', 'company', 'want', 'cover', 'whole', 'mumbai', 'especially', 'suburbs', 'distribution', 'products', 'include', 'rajrajeshwari', 'policy', 'women', 'metal', 'annual', 'international', 'conference', 'iron', 'steel', 'industry', 'hold', 'november', 'calcutta', 'seminar', 'organise', 'bengal', 'chamber', 'commerce', 'industry', 'bring', 'together', 'big', 'players', 'inthe', 'global', 'steel', 'sector', 'include', 'arcelor', 'ispat', 'international', 'posco', 'vip', 'industries', 'ltd', 'lead', 'luggage', 'manufacturer', 'bag', 'golden', 'peacock', 'innovation', 'award', 'institute', 'directors', 'product', 'emperor', 'deluxe', 'hummingbird', 'enterprise', 'legal', 'hummingbirds', 'endtoend', 'matter', 'lifecycle', 'management', 'solution', 'gain', 'widespread', 'acceptance', 'legal', 'community', 'deploy', 'worlds', 'largest', 'law', 'practice', 'professional', 'service', 'organisations', 'advertisement'], ['telegraph', 'calcutta', 'business', 'rbi', 'checklist', 'stop', 'homeloan', 'fraud', 'special', 'correspondent', 'mumbai', 'sept', 'panel', 'constitute', 'reserve', 'bank', 'india', 'today', 'ask', 'primary', 'urban', 'cooperative', 'bank', 'take', 'precaution', 'nine', 'key', 'areas', 'reduce', 'incidence', 'fraud', 'house', 'finance', 'concern', 'grow', 'menace', 'frauds', 'panel', 'tell', 'bank', 'careful', 'forgeries', 'title', 'document', 'multiple', 'finance', 'group', 'highlight', 'severity', 'fraud', 'pertain', 'multiple', 'finance', 'ask', 'bank', 'track', 'share', 'information', 'among', 'house', 'finance', 'company', 'hfcs', 'fraud', 'extension', 'fake', 'document', 'produce', 'different', 'bank', 'hfcs', 'group', 'say', 'also', 'urge', 'bank', 'share', 'information', 'blacklist', 'builders', 'developers', 'sell', 'properties', 'one', 'buyer', 'say', 'agreement', 'sale', 'document', 'title', 'demat', 'form', 'bank', 'hfcs', 'insist', 'original', 'title', 'deed', 'land', 'property', 'another', 'area', 'group', 'categorise', 'highrisk', 'forgery', 'title', 'document', 'stamp', 'paper', 'forge', 'borrowercustomer', 'builder', 'group', 'say', 'bank', 'track', 'share', 'information', 'name', 'blacklist', 'builders', 'developers', 'case', 'largevalue', 'loan', 'bank', 'approach', 'subregistrars', 'office', 'verify', 'genuineness', 'stamp', 'paperdocumentsregistration', 'receipt', 'among', 'others', 'group', 'also', 'point', 'frauds', 'relate', 'encashing', 'draft', 'third', 'partyagents', 'come', 'group', 'notice', 'loan', 'amount', 'disburse', 'way', 'cheque', 'demand', 'draft', 'encashed', 'third', 'party', 'agents', 'suggest', 'cheque', 'issue', 'name', 'bankers', 'builders', 'bankaccount', 'number', 'cheque', 'hand', 'borrower', 'agent', 'seller', 'bank', 'market', 'officials', 'send', 'delivery', 'cheque', 'builder', 'sellers', 'property', 'register', 'address', 'say', 'group', 'observe', 'incidence', 'overvaluation', 'property', 'whereby', 'higher', 'loan', 'amount', 'draw', 'borrower', 'connivance', 'builders', 'valuers', 'value', 'property', 'inflate', 'include', 'various', 'expense', 'additional', 'amenities', 'fixtures', 'legal', 'charge', 'society', 'advance', 'among', 'others', 'exist'], ['telegraph', 'calcutta', 'business', 'warn', 'note', 'slew', 'trade', 'sop', 'special', 'correspondent', 'commerce', 'minister', 'kamal', 'nath', 'ficci', 'seminar', 'new', 'delhi', 'wednesday', 'pti', 'new', 'delhi', 'sept', 'commerce', 'minister', 'kamal', 'nath', 'today', 'warn', 'exporters', 'new', 'incentive', 'scheme', 'target', 'plus', 'introduce', 'budget', 'misuse', 'make', 'fast', 'buck', 'say', 'exporters', 'ensure', 'dubious', 'mean', 'buy', 'export', 'company', 'show', 'inflate', 'growth', 'rat', 'order', 'claim', 'benefit', 'scheme', 'resort', 'similarly', 'illegal', 'practice', 'import', 'reexporting', 'gold', 'place', 'dubai', 'merely', 'show', 'company', 'notch', 'huge', 'export', 'gain', 'order', 'claim', 'incentives', 'also', 'eschew', 'customs', 'authorities', 'point', 'practice', 'use', 'unscrupulous', 'elements', 'claim', 'monetary', 'benefit', 'duty', 'entitlement', 'pass', 'book', 'scheme', 'finance', 'ministry', 'therefore', 'want', 'scheme', 'scrap', 'address', 'cii', 'meet', 'new', 'foreign', 'trade', 'policy', 'minister', 'say', 'government', 'unshackled', 'regulatory', 'mechanism', 'felt', 'per', 'cent', 'delinquent', 'elements', 'make', 'per', 'cent', 'honest', 'exporters', 'suffer', 'instance', 'need', 'bank', 'guarantee', 'do', 'away', 'would', 'result', 'save', 'per', 'cent', 'transaction', 'cost', 'make', 'export', 'competitive', 'however', 'exporters', 'must', 'respond', 'function', 'transparent', 'manner', 'live', 'expectations', 'government', 'add', 'nath', 'say', 'government', 'would', 'bring', 'trade', 'leverage', 'policy', 'apart', 'special', 'package', 'textiles', 'tea', 'coffee', 'sectors', 'india', 'never', 'leverage', 'trade', 'go', 'work', 'trade', 'leverage', 'policy', 'see', 'trade', 'net', 'forex', 'generator', 'net', 'forex', 'earner', 'say', 'ficci', 'seminar', 'national', 'foreign', 'trade', 'policy', 'need', 'special', 'emphasis', 'sectors', 'country', 'natural', 'abilities', 'add'], ['telegraph', 'calcutta', 'business', 'bengal', 'step', 'closer', 'vat', 'amit', 'chakraborty', 'calcutta', 'sept', 'move', 'step', 'closer', 'introduction', 'value', 'add', 'tax', 'west', 'bengal', 'government', 'today', 'bring', 'sweep', 'change', 'sales', 'tax', 'policy', 'shift', 'almost', 'commodities', 'consumables', 'singlepoint', 'tax', 'system', 'multipoint', 'one', 'items', 'exclude', 'drug', 'medicine', 'india', 'make', 'foreign', 'liquor', 'imfl', 'tea', 'change', 'policy', 'come', 'even', 'president', 'india', 'give', 'assent', 'west', 'bengal', 'value', 'add', 'tax', 'bill', 'however', 'presidential', 'assent', 'necessary', 'bring', 'policy', 'change', 'state', 'assembly', 'already', 'pass', 'bill', 'new', 'policy', 'small', 'retailers', 'spar', 'pay', 'sales', 'tax', 'big', 'retailers', 'gross', 'rs', 'lakh', 'would', 'charge', 'two', 'per', 'cent', 'turnover', 'tax', 'state', 'government', 'also', 'introduce', 'provision', 'voluntary', 'registration', 'small', 'businessmen', 'traders', 'irrespective', 'whether', 'pay', 'sales', 'tax', 'would', 'particularly', 'help', 'new', 'entrepreneurs', 'obtain', 'sales', 'tax', 'registration', 'essential', 'deal', 'government', 'departments', 'undertake', 'well', 'big', 'corporate', 'clients', 'earlier', 'sales', 'tax', 'registration', 'give', 'traders', 'gross', 'sales', 'rs', 'learn', 'c', 'bachawat', 'commissioner', 'commercial', 'tax', 'new', 'delhi', 'discuss', 'policy', 'union', 'finance', 'ministry', 'officials', 'senior', 'officials', 'directorate', 'commercial', 'tax', 'say', 'simplification', 'tax', 'administration', 'would', 'ensure', 'better', 'compliance', 'k', 'chatterjee', 'citybased', 'sales', 'tax', 'consultant', 'noncommittal', 'change', 'say', 'everything', 'would', 'depend', 'upon', 'implementation', 'case', 'imfl', 'drug', 'medicine', 'setoff', 'facility', 'provide', 'manufacturers', 'importers', 'manufacturers', 'dealers', 'imfl', 'give', 'option', 'pay', 'normal', 'rate', 'per', 'cent', 'maximum', 'retail', 'price', 'first', 'point', 'alternatively', 'pay', 'per', 'cent', 'multipoint', 'tax', 'structure', 'case', 'medicine', 'four', 'categories', 'rat', 'introduce', 'multipoint', 'basis', 'commercial', 'tax', 'directorate', 'spokesman', 'say', 'bharat', 'chamber', 'commerce', 'president', 'r', 'goenka', 'say', 'new', 'measure', 'would', 'advantageous', 'trade', 'industry', 'avoid', 'harassment', 'local', 'businessmen', 'goenka', 'say', 'chamber', 'demand', 'introduction', 'singlepoint', 'sales', 'tax', 'long', 'time', 'case', 'tea', 'tax', 'structure', 'decide', 'later', 'consult', 'various', 'industry', 'body'], ['telegraph', 'calcutta', 'business', 'raymond', 'bond', 'bangalore', 'special', 'correspondent', 'singhania', 'upbeat', 'mumbai', 'sept', 'raymond', 'ltd', 'textiles', 'apparel', 'major', 'today', 'announce', 'commencement', 'operations', 'subsidiary', 'silver', 'spark', 'apparel', 'ltd', 'bangalore', 'unit', 'manufacture', 'suit', 'formal', 'trousers', 'cater', 'largely', 'export', 'market', 'close', 'per', 'cent', 'suit', 'produce', 'unit', 'already', 'book', 'large', 'japanese', 'buyer', 'source', 'say', 'however', 'specify', 'till', 'book', 'last', 'entire', 'trouser', 'capacity', 'also', 'tie', 'till', 'march', 'add', 'manufacture', 'facility', 'locate', 'doddaballapur', 'near', 'bangalore', 'annual', 'capacity', 'five', 'lakh', 'suit', 'lakh', 'trousers', 'set', 'total', 'project', 'cost', 'rs', 'crore', 'units', 'commission', 'mark', 'raymond', 'group', 'foray', 'global', 'apparel', 'outsource', 'market', 'expect', 'significant', 'growth', 'quotas', 'dismantle', 'early', 'next', 'calendar', 'year', 'unit', 'total', 'builtup', 'area', 'square', 'feet', 'house', 'import', 'stateoftheart', 'manufacture', 'equipment', 'plant', 'specialise', 'make', 'superior', 'quality', 'jacket', 'line', 'italian', 'japanese', 'quality', 'level', 'two', 'place', 'know', 'best', 'jacket', 'world', 'fully', 'compliant', 'international', 'quality', 'norms', 'facility', 'audit', 'approve', 'commercial', 'production', 'major', 'american', 'japanese', 'mens', 'wear', 'buyers', 'raymond', 'say', 'statement', 'gautam', 'singhania', 'chairman', 'manage', 'director', 'raymond', 'ltd', 'say', 'investment', 'set', 'new', 'garment', 'unit', 'line', 'vision', 'become', 'global', 'player', 'areas', 'core', 'competence', 'unit', 'first', 'step', 'towards', 'bridge', 'valuechain', 'manufacture', 'fabrics', 'export', 'garment', 'raymond', 'chief', 'point', 'company', 'make', 'considerable', 'headway', 'fabrics', 'aim', 'major', 'player', 'apparel', 'segment', 'investments', 'towards', 'set', 'garment', 'manufacture', 'units', 'major', 'step', 'towards', 'achieve', 'goal', 'may', 'recall', 'earlier', 'year', 'raymond', 'unveil', 'rs', 'crore', 'expansion', 'programme', 'include', 'set', 'two', 'new', 'manufacture', 'units', 'apparel', 'denimwear', 'apart', 'expand', 'exist', 'denim', 'manufacture', 'capacity', 'company', 'also', 'set', 'denimwear', 'manufacture', 'facility', 'bangalore', 'annual', 'capacity', 'three', 'million', 'garment', 'total', 'project', 'cost', 'rs', 'crore', 'source', 'say', 'unit', 'call', 'ever', 'blue', 'apparel', 'ltd'], ['telegraph', 'calcutta', 'business', 'midas', 'touch', 'gold', 'charm', 'investors', 'satish', 'john', 'mumbai', 'sept', 'indians', 'buy', 'rs', 'crore', 'worth', 'gold', 'every', 'year', 'form', 'jewellery', 'investments', 'accord', 'world', 'gold', 'council', 'total', 'hold', 'yellow', 'metal', 'country', 'stand', 'tonnes', 'worth', 'rs', 'crore', 'part', 'annual', 'buy', 'come', 'housewives', 'stow', 'away', 'money', 'monthly', 'instalments', 'local', 'jeweller', 'purchase', 'aggregate', 'rs', 'crore', 'every', 'year', 'manage', 'director', 'sanjeev', 'agarwal', 'say', 'many', 'jewellers', 'cater', 'grow', 'demand', 'offer', 'gold', 'chit', 'scheme', 'allow', 'customer', 'buy', 'gold', 'ornament', 'coin', 'dealer', 'consolidate', 'amount', 'pay', 'instalments', 'housewives', 'save', 'rs', 'crore', 'every', 'year', 'recur', 'deposit', 'buy', 'gold', 'jewellery', 'do', 'outside', 'bank', 'sector', 'say', 'agarwal', 'council', 'say', 'india', 'us', 'west', 'asia', 'japan', 'china', 'account', 'per', 'cent', 'global', 'gold', 'purchase', 'annual', 'buy', 'rs', 'crore', 'comprise', 'mostly', 'new', 'gold', 'import', 'account', 'tonnes', 'value', 'rs', 'crore', 'tonnes', 'recycle', 'gold', 'hold', 'country', 'roughly', 'equal', 'rs', 'crore', 'save', 'bank', 'rs', 'crore', 'mutual', 'fund', 'accord', 'agarwal', 'household', 'save', 'rs', 'crore', 'hold', 'gold', 'bar', 'coin', 'india', 'buy', 'tonnes', 'gold', 'bar', 'coin', 'amount', 'rs', 'crore', 'every', 'year', 'fact', 'securities', 'exchange', 'board', 'india', 'ncaer', 'indicate', 'joint', 'study', 'bank', 'deposit', 'gold', 'second', 'prefer', 'save', 'instrument', 'world', 'gold', 'council', 'association', 'promote', 'usage', 'yellow', 'metal', 'advocate', 'gold', 'investment', 'option', 'superior', 'alternative', 'asset', 'class', 'currency', 'hedge', 'volatile', 'time', 'effective', 'guard', 'inflation', 'gold', 'price', 'skyrocket', 'recent', 'past', 'investments', 'give', 'true', 'return', 'long', 'term', 'agarwal', 'say', 'universal', 'asset', 'geographical', 'religious', 'socioeconomic', 'boundaries', 'add', 'performance', 'gold', 'link', 'company', 'industry', 'government', 'act', 'insurance', 'uncertainties', 'different', 'currencies', 'due', 'inverse', 'relationship', 'dollar', 'say', 'council', 'advocate', 'investment', 'portfolio', 'allocation', 'gold', 'improve', 'consistency', 'performance', 'stable', 'unstable', 'time', 'council', 'plead', 'government', 'authorities', 'reduce', 'customs', 'duties', 'allow', 'bank', 'offer', 'gold', 'loan', 'local', 'jewellers', 'councils', 'argument', 'jewellers', 'consume', 'rs', 'crore', 'gold', 'every', 'year'], ['telegraph', 'calcutta', 'business', 'tinplate', 'plan', 'rs', 'cr', 'expansion', 'new', 'delhi', 'sept', 'pti', 'major', 'expansion', 'drive', 'double', 'capacity', 'tata', 'group', 'firm', 'tinplate', 'company', 'india', 'today', 'say', 'would', 'invest', 'rs', 'crore', 'current', 'fiscal', 'set', 'new', 'plant', 'look', 'growth', 'potential', 'plan', 'step', 'capacity', 'earmark', 'rs', 'crore', 'expansion', 'plan', 'jamshedpur', 'plant', 'tinplate', 'sales', 'head', 'r', 'battish', 'say', 'capacity', 'electrolytic', 'tin', 'plant', 'would', 'go', 'lakh', 'tonnes', 'per', 'annum', 'current', 'lakh', 'tpa', 'propose', 'new', 'plant', 'double', 'capacity', 'three', 'lakh', 'tpa', 'first', 'quarter', 'log', 'rs', 'crore', 'net', 'profit', 'due', 'rise', 'steel', 'price', 'net', 'profit', 'next', 'two', 'quarter', 'could', 'drop', 'however', 'expect', 'end', 'fiscal', 'nearly', 'flat', 'battish', 'say'], ['telegraph', 'calcutta', 'business', 'wto', 'win', 'yet', 'sink', 'special', 'correspondent', 'new', 'delhi', 'sept', 'commerce', 'minister', 'kamal', 'nath', 'today', 'strike', 'cautious', 'note', 'wto', 'victory', 'us', 'antidumping', 'duties', 'say', 'come', 'constructive', 'response', 'minister', 'tell', 'telegraph', 'still', 'process', 'firm', 'response', 'constructive', 'ask', 'comment', 'wto', 'rule', 'nath', 'say', 'clearly', 'demonstrate', 'us', 'distort', 'trade', 'develop', 'countries', 'get', 'level', 'play', 'field', 'india', 'along', 'eu', 'six', 'countries', 'include', 'japan', 'south', 'korea', 'brazil', 'mexico', 'get', 'goahead', 'impose', 'sanction', 'tune', 'million', 'us', 'goods', 'retaliation', 'antidumping', 'duties', 'impose', 'controversial', 'byrd', 'amendment', 'eu', 'trade', 'commissioner', 'pascal', 'lamy', 'already', 'appeal', 'us', 'repeal', 'controversial', 'law', 'order', 'avoid', 'risk', 'sanction', 'us', 'impose', 'antidumping', 'duty', 'steel', 'ballbearings', 'pasta', 'seafood', 'report', 'collect', 'around', 'million', 'account', 'duties', 'last', 'three', 'years', 'cover', 'byrd', 'amendment', 'pass', 'duties', 'us', 'company', 'engage', 'businesses', 'twothirds', 'money', 'collect', 'japanese', 'firm', 'indian', 'company', 'steel', 'authority', 'india', 'ltd', 'tata', 'steel', 'also', 'export', 'steel', 'us', 'export', 'seafood', 'well', 'however', 'heavy', 'antidumping', 'duty', 'impose', 'indian', 'shrimp', 'lead', 'suspension', 'export']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbrARAfX69S0"
      },
      "source": [
        "After the preprocessing is over we can move towards fiting and transforming the text to vectors.The preprocessed data is contained in lemmatized_data variable .structure of lemmatize data is as follows\r\n",
        "\r\n",
        "lemmatized_data = [ [document1] , [document2] , ....                  [documentn] ]\r\n",
        "where each document within the list contains the preprocessed list of words contained in that particular document\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0qJKdXk7Mp6"
      },
      "source": [
        "# 3.**Making custom class for TF-IDF**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVfoRy7m9MDR"
      },
      "source": [
        "following is the implementation of fit and Transform function . fit function will return the term_document matrix and transform function will take argument a document and will return term document matrix of that particular document"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skjY1Rik7h6n"
      },
      "source": [
        "class TFIDF:\r\n",
        "  def __init__(self,pre_processeddata):\r\n",
        "    self.data = pre_processeddata\r\n",
        "    #getting the unique list of words over all the document\r\n",
        "    self.unique_list = self.extractUnique(pre_processeddata)\r\n",
        "    ##sorting the features\r\n",
        "    self.feature_list = sorted(self.unique_list)\r\n",
        "    ##mapping unique words to particular number \r\n",
        "    self.unique_dict_words ={self.feature_list[i] : i for i in range(len(self.feature_list))}\r\n",
        "    ##initializing term document matrix \r\n",
        "    global doc\r\n",
        "    self.term_document_matrix = np.zeros((len(doc),len(self.unique_dict_words)))\r\n",
        "    ##initializing idf_matrix\r\n",
        "    self.idf_matrix = np.zeros((1,len(self.unique_dict_words)))\r\n",
        "    \r\n",
        "\r\n",
        "  #fit function will return term document matrix\r\n",
        "  def fit(self,documents):\r\n",
        "    #finding term-frequency matrix\r\n",
        "    term_frequency_matrix = self.find_term_matrix(documents)\r\n",
        "    #finding idf_matrix\r\n",
        "    self.idf_matrix = self.find_idf_matrix()\r\n",
        "    \r\n",
        "    \r\n",
        "    #broadcasting idf_matrix to every other documents\r\n",
        "    broadcasted_idf_matrix = np.zeros((len(documents),len(self.feature_list)))\r\n",
        "    for i in range(len(documents)):\r\n",
        "      broadcasted_idf_matrix[i:] = self.idf_matrix\r\n",
        "    \r\n",
        "    #calculating term document_matrix\r\n",
        "  \r\n",
        "    #element wise multiplication using np.multiply \r\n",
        "    #multiplying term-frequency matrix with broadcasted_idf_matrix\r\n",
        "\r\n",
        "    self.term_document_matrix = np.multiply(term_frequency_matrix,broadcasted_idf_matrix) \r\n",
        "   \r\n",
        "    return self.term_document_matrix\r\n",
        "\r\n",
        "  \r\n",
        "  #transform will return term document matrix for the particular document\r\n",
        "  def transform(self,document):\r\n",
        "    #computing term frequency in the document\r\n",
        "    #returns term_doc_matrix\r\n",
        "    tf_matrix  = np.array(self.find_term_matrix(document))\r\n",
        "    return np.multiply(tf_matrix, self.idf_matrix)\r\n",
        "    \r\n",
        "  \r\n",
        "  def find_term_matrix(self,documents):\r\n",
        "    global lemmatized_data\r\n",
        "    term_frequency_matrix = list()\r\n",
        "    if type(documents[0]) is not list:\r\n",
        "      document = documents\r\n",
        "      total_words=len(lemmatized_data[lemmatized_data.index(document)])\r\n",
        "      document_frequency = list()\r\n",
        "      for word in self.feature_list :\r\n",
        "        count = document.count(word)\r\n",
        "        document_frequency.append(count/total_words)\r\n",
        "      term_frequency_matrix.append(document_frequency)\r\n",
        "      return term_frequency_matrix\r\n",
        "    else:\r\n",
        "      \r\n",
        "      for document in documents:\r\n",
        "        doc_id = lemmatized_data.index(document)\r\n",
        "        total_words_in_doc = len(lemmatized_data[doc_id])\r\n",
        "        document_frequency = list()\r\n",
        "        for word in self.feature_list:\r\n",
        "          count = document.count(word)\r\n",
        "          document_frequency.append(count/total_words_in_doc)\r\n",
        "        term_frequency_matrix.append(document_frequency)\r\n",
        "      return term_frequency_matrix\r\n",
        "  \r\n",
        "  def find_idf_matrix(self):\r\n",
        "    #return list which stores the idf value of each unique term\r\n",
        "    global lemmatized_data\r\n",
        "    \r\n",
        "    idf_matrix=list()\r\n",
        "    for word in self.feature_list:\r\n",
        "      \r\n",
        "      #count no of document containing the particular term\r\n",
        "      count=0\r\n",
        "      for document in lemmatized_data:\r\n",
        "        if word in document:\r\n",
        "          count += 1\r\n",
        "        \r\n",
        "      #finding idf using formula math.log10(N / float(freq)\r\n",
        "      value = len(lemmatized_data)/float(count)\r\n",
        "      idf = math.log10(value)\r\n",
        "      \r\n",
        "      idf_matrix.append(idf)\r\n",
        "    return idf_matrix\r\n",
        "\r\n",
        "  \r\n",
        "  def extractUnique(self,data):\r\n",
        "    #In all words we are storing all the words taken from different doc\r\n",
        "    all_words = list()\r\n",
        "    for i,doc_value in zip(range(len(data)),data):\r\n",
        "          for word in doc_value:\r\n",
        "            all_words.append(word)\r\n",
        "    #returning the list   of unique words from the all_words\r\n",
        "    #first we convert the list to set so that it only contains unique elements\r\n",
        "    #afterwards we convert it back to list because we want to work with the list data\r\n",
        "    all_words_set = set(all_words)\r\n",
        "    all_unique_words = list(all_words_set)\r\n",
        "    return all_unique_words\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNalft497VhM"
      },
      "source": [
        "#**creating object of TFIDF class and then calling fit and transform function using that object.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTv5gujJI9Ov"
      },
      "source": [
        "obj_tfidf = TFIDF(lemmatized_data) #created object of TFIDF class\r\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n06CMuHTJoZc",
        "outputId": "fd05c7a2-13b2-4312-a060-880629dee67d"
      },
      "source": [
        "term_doc_matrix = obj_tfidf.fit(lemmatized_data) #calling fit function\r\n",
        " \r\n",
        "print(term_doc_matrix.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16, 1578)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKyI-h4c-cjU"
      },
      "source": [
        "passing the document to transform function and it must return term document matrix of that particular document"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wiw_4khpX0p",
        "outputId": "60371296-493b-45aa-d88f-f54b83546088"
      },
      "source": [
        "data = obj_tfidf.transform(lemmatized_data[0]) #calling transform function.\r\n",
        "print(data.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1578)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsxbdjZ74tYs"
      },
      "source": [
        "#**4 using sklearn tfidf vectorizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7eUYvv06OhN",
        "outputId": "4f0e1a17-2a50-4950-b667-560a6578df42"
      },
      "source": [
        "\r\n",
        "global doc\r\n",
        "\r\n",
        "data  = obj.load_data()                                                                         #load_data\r\n",
        "\r\n",
        "corpus = list()\r\n",
        "document_array=list()\r\n",
        "\r\n",
        "for i,value in zip(range(len(data)),data):\r\n",
        "  corpus.append(value)\r\n",
        "  document_array.append(str(doc[i]));\r\n",
        "\r\n",
        "vectorizer = TfidfVectorizer(analyzer='word' , stop_words='english',)                          #preprocessing\r\n",
        "X = vectorizer.fit_transform(corpus)                                                           #fetching object of term document matrix \r\n",
        "tfidf_tokens = vectorizer.get_feature_names()                                                  #getting feature names\r\n",
        "df_tfidfvect = pd.DataFrame(data = X.toarray(),index = document_array,columns = tfidf_tokens)  #panda dataframe\r\n",
        "print(X.shape)\r\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16, 1932)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QEZu2tzJoxt"
      },
      "source": [
        "Here we can see that using sklearn library for tfidf vectorization ,it generates more unique words compared to our custom made approach , this is because the inbuilt library does not lemmatize the data hence for a single root word there may be more than one word belonging to the same word family..for example if a document contains **\"document\"** and **\"documentation\"** word, our method will lemmatize the **\"documentation\"** to **\"document\"** and hence producing only one root word which is **\"document\"** , but sklearn tdfidf vectorizer doesnot do this particular lemmatization and hence this words are treated differently therefore we can see more number of words in the sklearn tdfdf vectorizer compared to custom made tdfidf vectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY5TTNkUgzfo"
      },
      "source": [
        "#**5.Showing top 5 words representing each document from the first five document using sklearn tdfvectorizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "E59LwZEphB92",
        "outputId": "21cf15d6-c1cb-46fb-cab8-f7f37ec018aa"
      },
      "source": [
        "first_five_doc = [str(ele) for ele in doc[0:5]]                                       #first five doc \r\n",
        "\r\n",
        "required_data_frame  = df_tfidfvect.head(5)                               #fetching panda dataframe for first five doc\r\n",
        "\r\n",
        "\r\n",
        "for i in range(5):\r\n",
        "  df1 = required_data_frame.iloc[i:] #fetching the data from ith row to last row\r\n",
        "  one_row = df1.head(1) #fetching the first record \r\n",
        "  dfObj = one_row.sort_values(by = first_five_doc[i], ascending=False,axis=1) #sorting accordind to columns in descending order\r\n",
        "  dfObj = dfObj.iloc[:,0:5]  #fetching top 5 columns\r\n",
        "  dataframe = pd.DataFrame(dfObj)\r\n",
        "  display(dataframe)\r\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>consolidation</th>\n",
              "      <th>content</th>\n",
              "      <th>idbi</th>\n",
              "      <th>enterprise</th>\n",
              "      <th>crore</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>&lt;docno&gt;1040901_business_story_3700171.utf8&lt;/docno&gt;</th>\n",
              "      <td>0.181529</td>\n",
              "      <td>0.181529</td>\n",
              "      <td>0.181529</td>\n",
              "      <td>0.158089</td>\n",
              "      <td>0.157629</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    consolidation  ...     crore\n",
              "<docno>1040901_business_story_3700171.utf8</docno>       0.181529  ...  0.157629\n",
              "\n",
              "[1 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>policy</th>\n",
              "      <th>trade</th>\n",
              "      <th>foreign</th>\n",
              "      <th>export</th>\n",
              "      <th>exports</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>&lt;docno&gt;1040901_business_story_3700827.utf8&lt;/docno&gt;</th>\n",
              "      <td>0.298825</td>\n",
              "      <td>0.244493</td>\n",
              "      <td>0.195369</td>\n",
              "      <td>0.162808</td>\n",
              "      <td>0.162808</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      policy  ...   exports\n",
              "<docno>1040901_business_story_3700827.utf8</docno>  0.298825  ...  0.162808\n",
              "\n",
              "[1 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>centre</th>\n",
              "      <th>patni</th>\n",
              "      <th>professionals</th>\n",
              "      <th>financial</th>\n",
              "      <th>chennai</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>&lt;docno&gt;1040901_business_story_3701515.utf8&lt;/docno&gt;</th>\n",
              "      <td>0.375359</td>\n",
              "      <td>0.331264</td>\n",
              "      <td>0.198759</td>\n",
              "      <td>0.198759</td>\n",
              "      <td>0.173094</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      centre  ...   chennai\n",
              "<docno>1040901_business_story_3701515.utf8</docno>  0.375359  ...  0.173094\n",
              "\n",
              "[1 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bharat</th>\n",
              "      <th>petro</th>\n",
              "      <th>corporation</th>\n",
              "      <th>refineries</th>\n",
              "      <th>kochi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>&lt;docno&gt;1040901_business_story_3701518.utf8&lt;/docno&gt;</th>\n",
              "      <td>0.4327</td>\n",
              "      <td>0.361351</td>\n",
              "      <td>0.211189</td>\n",
              "      <td>0.180675</td>\n",
              "      <td>0.180675</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    bharat  ...     kochi\n",
              "<docno>1040901_business_story_3701518.utf8</docno>  0.4327  ...  0.180675\n",
              "\n",
              "[1 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>01</th>\n",
              "      <th>10</th>\n",
              "      <th>16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>&lt;docno&gt;1040901_business_story_3701887.utf8&lt;/docno&gt;</th>\n",
              "      <td>0.304561</td>\n",
              "      <td>0.279866</td>\n",
              "      <td>0.207941</td>\n",
              "      <td>0.202783</td>\n",
              "      <td>0.198489</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                          11  ...        16\n",
              "<docno>1040901_business_story_3701887.utf8</docno>  0.304561  ...  0.198489\n",
              "\n",
              "[1 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgjLhGuEHpn2"
      },
      "source": [
        "Here, Above Top 5 words for the first 5 respective document is shown..first column word for each document is having 1st rank ,second column word has second rank and so on up to 5th columnar word.The value at each cell is the corresponding tf-idf score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai22wdWZ4-yI"
      },
      "source": [
        "#**5.1 showing top 5 words representing each document from the first 5 documents using custom approach**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KOwy1NPs5IOr",
        "outputId": "cbdf359d-a1cd-4aeb-f95b-6ce0a3bc6d9a"
      },
      "source": [
        "for i in range(5):\r\n",
        "  T_D_M  = obj_tfidf.term_document_matrix\r\n",
        "  tf_idf_doc = T_D_M[i]\r\n",
        "  tf_idf_pair = [(i,tfidf) for i,tfidf in zip(range(len(obj_tfidf.feature_list)),tf_idf_doc)]\r\n",
        "  tf_idf_pair.sort(key= lambda ele:ele[1],reverse=True)\r\n",
        "  first_five = tf_idf_pair[0:5]\r\n",
        "  global doc\r\n",
        "  print(\"\\n\\ndocument=\",doc[i])\r\n",
        "  X=list()\r\n",
        "  rank=1\r\n",
        "  for pair in first_five:\r\n",
        "    #fetching tf-idf score\r\n",
        "    tf_idf = pair[1]\r\n",
        "    word_code =pair[0]\r\n",
        "    #fetching word from word_code\r\n",
        "    word = obj_tfidf.feature_list[word_code]\r\n",
        "    X.append([rank,word,tf_idf])\r\n",
        "    rank += 1\r\n",
        "  dframe = pd.DataFrame(data = X,columns = [\"rank\",\"word\",\"tf-idf-score\"])    \r\n",
        "  print(\"\\n\")\r\n",
        "  display(dframe)\r\n",
        "  \r\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "document= <docno>1040901_business_story_3700171.utf8</docno>\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rank</th>\n",
              "      <th>word</th>\n",
              "      <th>tf-idf-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>consolidation</td>\n",
              "      <td>0.014566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>content</td>\n",
              "      <td>0.014566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>idbi</td>\n",
              "      <td>0.014566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>award</td>\n",
              "      <td>0.010924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>enterprise</td>\n",
              "      <td>0.010924</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rank           word  tf-idf-score\n",
              "0     1  consolidation      0.014566\n",
              "1     2        content      0.014566\n",
              "2     3           idbi      0.014566\n",
              "3     4          award      0.010924\n",
              "4     5     enterprise      0.010924"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "document= <docno>1040901_business_story_3700827.utf8</docno>\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rank</th>\n",
              "      <th>word</th>\n",
              "      <th>tf-idf-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>policy</td>\n",
              "      <td>0.013553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>export</td>\n",
              "      <td>0.013216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>foreign</td>\n",
              "      <td>0.010639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>competitiveness</td>\n",
              "      <td>0.008811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>earn</td>\n",
              "      <td>0.008811</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rank             word  tf-idf-score\n",
              "0     1           policy      0.013553\n",
              "1     2           export      0.013216\n",
              "2     3          foreign      0.010639\n",
              "3     4  competitiveness      0.008811\n",
              "4     5             earn      0.008811"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "document= <docno>1040901_business_story_3701515.utf8</docno>\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rank</th>\n",
              "      <th>word</th>\n",
              "      <th>tf-idf-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>patni</td>\n",
              "      <td>0.033448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>centre</td>\n",
              "      <td>0.026758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>financial</td>\n",
              "      <td>0.020069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>professionals</td>\n",
              "      <td>0.020069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>chennai</td>\n",
              "      <td>0.015051</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rank           word  tf-idf-score\n",
              "0     1          patni      0.033448\n",
              "1     2         centre      0.026758\n",
              "2     3      financial      0.020069\n",
              "3     4  professionals      0.020069\n",
              "4     5        chennai      0.015051"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "document= <docno>1040901_business_story_3701518.utf8</docno>\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rank</th>\n",
              "      <th>word</th>\n",
              "      <th>tf-idf-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>bharat</td>\n",
              "      <td>0.034137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>petro</td>\n",
              "      <td>0.028965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>kochi</td>\n",
              "      <td>0.016551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>refineries</td>\n",
              "      <td>0.016551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>corporation</td>\n",
              "      <td>0.014990</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rank         word  tf-idf-score\n",
              "0     1       bharat      0.034137\n",
              "1     2        petro      0.028965\n",
              "2     3        kochi      0.016551\n",
              "3     4   refineries      0.016551\n",
              "4     5  corporation      0.014990"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "document= <docno>1040901_business_story_3701887.utf8</docno>\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rank</th>\n",
              "      <th>word</th>\n",
              "      <th>tf-idf-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>uti</td>\n",
              "      <td>0.061606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>equity</td>\n",
              "      <td>0.033603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>hdfc</td>\n",
              "      <td>0.029870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>income</td>\n",
              "      <td>0.029870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>mip</td>\n",
              "      <td>0.029870</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rank    word  tf-idf-score\n",
              "0     1     uti      0.061606\n",
              "1     2  equity      0.033603\n",
              "2     3    hdfc      0.029870\n",
              "3     4  income      0.029870\n",
              "4     5     mip      0.029870"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpaNLEGAZt07"
      },
      "source": [
        "#observation\r\n",
        "As we can see using sklearn library v/s using custom method .the result slightly varies but not up to a great extent it is because this difference noted is majorly because of the different preprocessing approach and the different formula for calculation of inverse document frequency."
      ]
    }
  ]
}